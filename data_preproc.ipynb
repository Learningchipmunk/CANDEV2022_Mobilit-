{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "import time\n",
    "# sklearn?\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1405579, 35)\n",
      "Index(['LEVEL1ID', 'LEVEL2ID', 'LEVEL3ID', 'LEVEL4ID', 'LEVEL5ID', 'SURVEYR',\n",
      "       'BYCOND', 'DESCRIP_E', 'DESCRIP_F', 'DEMCODE', 'QUESTION', 'TITLE_E',\n",
      "       'TITLE_F', 'ANSWER1', 'ANSWER2', 'ANSWER3', 'ANSWER4', 'ANSWER5',\n",
      "       'ANSWER6', 'ANSWER7', 'MOST_POSITIVE_OR_LEAST_NEGATIVE',\n",
      "       'NEUTRAL_OR_MIDDLE_CATEGORY', 'MOST_NEGATIVE_OR_LEAST_POSITIVE',\n",
      "       'AGREE', 'SCORE5', 'SCORE100', 'ANSCOUNT', 'DEPT_E', 'DEPT_F',\n",
      "       'INDICATORID', 'INDICATORENG', 'INDICATORFRA', 'SUBINDICATORID',\n",
      "       'SUBINDICATORENG', 'SUBINDICATORFRA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_origin = pd.read_csv(\"Data/subset-3-sous-ensemble-3.csv\", encoding='latin1')\n",
    "print(data_origin.shape)\n",
    "print(data_origin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583123, 20)\n",
      "Index(['LEVEL1ID', 'SURVEYR', 'DEMCODE', 'QUESTION', 'ANSWER1', 'ANSWER2',\n",
      "       'ANSWER3', 'ANSWER4', 'ANSWER5', 'ANSWER6', 'ANSWER7',\n",
      "       'MOST_POSITIVE_OR_LEAST_NEGATIVE', 'NEUTRAL_OR_MIDDLE_CATEGORY',\n",
      "       'MOST_NEGATIVE_OR_LEAST_POSITIVE', 'AGREE', 'SCORE5', 'ANSCOUNT',\n",
      "       'INDICATORID', 'SUBINDICATORID', 'ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = data_origin.copy()\n",
    "\n",
    "# drop columns with only 1 value\n",
    "# empty = []\n",
    "# for col in data.columns:\n",
    "#     uni = data[col].unique()\n",
    "#     if len(uni)<2:\n",
    "#         print(col, uni)\n",
    "#         data.drop(columns=[col], inplace=True)\n",
    "try: data.drop(columns=['LEVEL2ID', 'LEVEL3ID', 'LEVEL4ID', 'LEVEL5ID'], inplace=True)\n",
    "except: pass\n",
    "\n",
    "# drop useless columns\n",
    "# DEMCODE = BYCOND, DESCRIP_E, DESCRIP_F\n",
    "# QUESTION = TITLE_E, TITLE_F\n",
    "# INDICATORID = INDICATORENG, INDICATORFRA\n",
    "# SUBINDICATORID = SUBINDICATORENG, SUBINDICATORFRA\n",
    "# LEVEL1ID = DEPT_E, DEPT_F\n",
    "# SCORE5 = X*SCORE100 + Y\n",
    "useless = ['BYCOND', 'DESCRIP_E', 'DESCRIP_F', 'TITLE_E', 'TITLE_F', 'SUBINDICATORENG', 'SUBINDICATORFRA', 'DEPT_E', 'DEPT_F', 'INDICATORENG', 'INDICATORFRA', 'SCORE100']\n",
    "try: data.drop(columns=useless, inplace=True)\n",
    "except: pass\n",
    "\n",
    "# drop empty lines\n",
    "data.drop(data[data['ANSWER1'] == ' '].index, inplace=True)\n",
    "\n",
    "# change strings to numbers\n",
    "traduction_question = {ques: i+101 for i, ques in enumerate(data['QUESTION'].unique())}\n",
    "data['QUESTION'] = data['QUESTION'].map(lambda x: traduction_question[x])\n",
    "\n",
    "data = data.astype({'SCORE5': 'float'}, copy=False)\n",
    "data = data.astype({col: 'int' for col in ['ANSWER1', 'ANSWER2', 'ANSWER3', 'ANSWER4', 'ANSWER5', 'ANSWER6', 'ANSWER7',\n",
    "    'MOST_POSITIVE_OR_LEAST_NEGATIVE', 'NEUTRAL_OR_MIDDLE_CATEGORY', 'MOST_NEGATIVE_OR_LEAST_POSITIVE', 'AGREE',\n",
    "    'ANSCOUNT']}, copy=False)\n",
    "\n",
    "# add unique ids to each participant\n",
    "data['ID'] = data['LEVEL1ID']*1000 + (data['SURVEYR']-2018)*100 + data['DEMCODE']-2011\n",
    "\n",
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEVEL1ID \t 68 \t <class 'numpy.int64'> \t 0\n",
      "SURVEYR \t 3 \t <class 'numpy.int64'> \t 2020\n",
      "DEMCODE \t 59 \t <class 'numpy.int64'> \t 2011\n",
      "QUESTION \t 216 \t <class 'numpy.int64'> \t 101\n",
      "ANSWER1 \t 101 \t <class 'numpy.int64'> \t 35\n",
      "ANSWER2 \t 101 \t <class 'numpy.int64'> \t 45\n",
      "ANSWER3 \t 87 \t <class 'numpy.int64'> \t 6\n",
      "ANSWER4 \t 71 \t <class 'numpy.int64'> \t 11\n",
      "ANSWER5 \t 82 \t <class 'numpy.int64'> \t 3\n",
      "ANSWER6 \t 74 \t <class 'numpy.int64'> \t 0\n",
      "ANSWER7 \t 65 \t <class 'numpy.int64'> \t 0\n",
      "MOST_POSITIVE_OR_LEAST_NEGATIVE \t 102 \t <class 'numpy.int64'> \t 81\n",
      "NEUTRAL_OR_MIDDLE_CATEGORY \t 86 \t <class 'numpy.int64'> \t 6\n",
      "MOST_NEGATIVE_OR_LEAST_POSITIVE \t 98 \t <class 'numpy.int64'> \t 14\n",
      "AGREE \t 102 \t <class 'numpy.int64'> \t 81\n",
      "SCORE5 \t 366 \t <class 'numpy.float64'> \t 3.99\n",
      "ANSCOUNT \t 15718 \t <class 'numpy.int64'> \t 73497\n",
      "INDICATORID \t 6 \t <class 'numpy.int64'> \t 4\n",
      "SUBINDICATORID \t 23 \t <class 'numpy.int64'> \t 14\n",
      "ID \t 4992 \t <class 'numpy.int64'> \t 200\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col, '\\t', len(data[col].unique()), '\\t', type(data[col][0]), '\\t', data[col][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4992, 3244)\n",
      "Index(['ID', 'ANSWER1_101', 'ANSWER2_101', 'ANSWER3_101', 'ANSWER4_101',\n",
      "       'ANSWER5_101', 'ANSWER6_101', 'ANSWER7_101',\n",
      "       'MOST_POSITIVE_OR_LEAST_NEGATIVE_101', 'NEUTRAL_OR_MIDDLE_CATEGORY_101',\n",
      "       ...\n",
      "       'NEUTRAL_OR_MIDDLE_CATEGORY_316', 'MOST_NEGATIVE_OR_LEAST_POSITIVE_316',\n",
      "       'AGREE_316', 'SCORE5_316', 'ANSCOUNT_316', 'INDICATORID_316',\n",
      "       'SUBINDICATORID_316', 'LEVEL1ID', 'SURVEYR', 'DEMCODE'],\n",
      "      dtype='object', length=3244)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1166/1844093436.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_agg['LEVEL1ID'] = data_agg['ID'] // 1000\n",
      "/tmp/ipykernel_1166/1844093436.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_agg['SURVEYR'] = (data_agg['ID'] // 100) % 10 + 2018\n",
      "/tmp/ipykernel_1166/1844093436.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_agg['DEMCODE'] = data_agg['ID'] % 100 + 2011\n"
     ]
    }
   ],
   "source": [
    "data_questions = data.drop(columns = ['SURVEYR', 'DEMCODE', 'LEVEL1ID'])\n",
    "list_id = data_questions['ID'].unique()\n",
    "set_id = set(list_id)\n",
    "data_agg = pd.DataFrame({'ID' : list_id})\n",
    "\n",
    "for i in range(101, 317):\n",
    "    new_question = data_questions[data_questions['QUESTION']==i].drop(columns = ['QUESTION'])\n",
    "    missing_id = list(set_id-set(new_question['ID']))\n",
    "        \n",
    "    new_df = pd.DataFrame({name: ([0]*len(missing_id) if index<len(new_question.columns)-1 else missing_id) for index, name in enumerate(new_question.columns)})\n",
    "    new_question = new_question.append(new_df, ignore_index = True)\n",
    "            \n",
    "    new_question.rename(columns=lambda x: x + \"_\" + str(i) if x!='ID' else x, inplace=True)\n",
    "    data_agg = pd.merge(data_agg, new_question, on = 'ID')\n",
    "\n",
    "data_agg['LEVEL1ID'] = data_agg['ID'] // 1000\n",
    "data_agg['SURVEYR'] = (data_agg['ID'] // 100) % 10 + 2018\n",
    "data_agg['DEMCODE'] = data_agg['ID'] % 100 + 2011\n",
    "\n",
    "print(data_agg.shape)\n",
    "print(data_agg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
